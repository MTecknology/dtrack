{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About DTrack Disturbance Track (DTrack) offers 24/7 monitoring that uses Machine Learning (AI) to identify disturbing noises, such as dog barking or car alarms. Rather than using expensive \"cloud\" infrastructure for advanced categorization, DTrack creates a model that is trained to detect only the exact noise that it was trained on. This helps eliminate false positives and decreases the effort required to perform matching. How It Works Set up the Monitoring Device Collect some initial recordings Train a model from collected recordings Use trained model for automatic detection Why It Exists In some jurisdictions, understaffing leads to complete dismissal of any call that is not life threatening. In these cases, even a detailed report of ongoing noise disturbances may be entirely dismissed without a full 48 hours of detailed (to-the-minute) logging of every single occurrence, alongside submitted video. Painstakingly listening to this audio in order to accurately log each and every disturbance, unsurprisingly, adds to overall frustration, but it also yields a report that is guaranteed to be taken seriously by a District Attorney. DTrack exists to provide an initial report that can be easily reviewed in much less time. How Is This Possible? Most scoffs at this endevour have come from an understanding that large datasets are huge and take a tremendous amount of power to work with, making it impossible to keep detection entirely within lightweight hardware. This comes from a fundamental misunderstanding of what detection is actually needed. Consider which of the following questions is easier for a computer to answer: Is a banana present in this image? Is a whole, pristine, ripe, yellow banana present in this image? The former can include any type of banana. It could still be green, or perhaps yellow but cut in half, or brown and smashed. At what point of decay is it no longer a banana? Large data models take all of these questions into consideration and then try to apply tags that answer yes or no to each question. Disturbance Tracker only cares about the tag that it was trained to detect, which eliminates extra overhead and makes detection a very lightweight operation.","title":"Temp"},{"location":"#about-dtrack","text":"Disturbance Track (DTrack) offers 24/7 monitoring that uses Machine Learning (AI) to identify disturbing noises, such as dog barking or car alarms. Rather than using expensive \"cloud\" infrastructure for advanced categorization, DTrack creates a model that is trained to detect only the exact noise that it was trained on. This helps eliminate false positives and decreases the effort required to perform matching.","title":"About DTrack"},{"location":"#how-it-works","text":"Set up the Monitoring Device Collect some initial recordings Train a model from collected recordings Use trained model for automatic detection","title":"How It Works"},{"location":"#why-it-exists","text":"In some jurisdictions, understaffing leads to complete dismissal of any call that is not life threatening. In these cases, even a detailed report of ongoing noise disturbances may be entirely dismissed without a full 48 hours of detailed (to-the-minute) logging of every single occurrence, alongside submitted video. Painstakingly listening to this audio in order to accurately log each and every disturbance, unsurprisingly, adds to overall frustration, but it also yields a report that is guaranteed to be taken seriously by a District Attorney. DTrack exists to provide an initial report that can be easily reviewed in much less time.","title":"Why It Exists"},{"location":"#how-is-this-possible","text":"Most scoffs at this endevour have come from an understanding that large datasets are huge and take a tremendous amount of power to work with, making it impossible to keep detection entirely within lightweight hardware. This comes from a fundamental misunderstanding of what detection is actually needed. Consider which of the following questions is easier for a computer to answer: Is a banana present in this image? Is a whole, pristine, ripe, yellow banana present in this image? The former can include any type of banana. It could still be green, or perhaps yellow but cut in half, or brown and smashed. At what point of decay is it no longer a banana? Large data models take all of these questions into consideration and then try to apply tags that answer yes or no to each question. Disturbance Tracker only cares about the tag that it was trained to detect, which eliminates extra overhead and makes detection a very lightweight operation.","title":"How Is This Possible?"},{"location":"setup/configure/","text":"Configuration DTrack has defaults that are designed to function adequately on a Raspberry Pi 5, although these make very poor monitoring devices. If your Selected Hardware provides a hardware video en conder, then it is important to modify record_save_options (below). config.json Configuration is stored in a JSON file, called config.json . A sample can be copied from example_config.json , or a file can be created from any single option. Important JSON Gotchas: Format: { \"KEY\": VALUE, \"KEY\": VALUE, \"KEY\": VALUE } All VALUE s are one of: string : \"anythin inside of quotes\" list : [\"like\", \"a\", \"string\", \"broken\", \"into\", \"parts\"] number : 5 or 3.1415 boolean : true for Yes or false for No Every VALUE must have a trailing comma ( , ), except the last must not. Defaults Defaults were selected based on testing with lowest-recommended hardware. Baseline Command: ffmpeg -y -loglevel warning -nostdin -nostats \\ -t 00:10:00 -f alsa -i plughw \\ -t 00:10:00 -f v4l2 -i /dev/video0 \\ -map 0:a -c:a pcm_s16le -ar 48000 -ac 1 -f wav - \\ -filter_complex [1:v]...[dtstamp] -map 0:a -map [dtstamp] \\ -c:a pcm_s16le -ar 48000 -ac 1 -c:v libx264 -tune zerolatency baseline.mkv \\ >/dev/null Test-Driven Defaults: Encoder Documentation <https://trac.ffmpeg.org/wiki/Encode/H.264> __ -t <time> must be set prior to each input -tune zerolatency is required for software encoding on low-end cpu -bufsize 64M : Very large buffer to helps avoid processing spikes -crf 23 : Default is best; 25 reduces size by 30%, but 24 creates movement -maxrate 3M : Hard quality limit, based on NO hardware encoding 1080p recordings will see quality improvement up to about 7M Larger value creates larger files and XBUF for CPU-only encoding -preset fast : Yield fewest XRUN errors -framerate 15 : Fast enough to catch most movement","title":"Configuration File"},{"location":"setup/configure/#configuration","text":"DTrack has defaults that are designed to function adequately on a Raspberry Pi 5, although these make very poor monitoring devices. If your Selected Hardware provides a hardware video en conder, then it is important to modify record_save_options (below).","title":"Configuration"},{"location":"setup/configure/#configjson","text":"Configuration is stored in a JSON file, called config.json . A sample can be copied from example_config.json , or a file can be created from any single option. Important JSON Gotchas: Format: { \"KEY\": VALUE, \"KEY\": VALUE, \"KEY\": VALUE } All VALUE s are one of: string : \"anythin inside of quotes\" list : [\"like\", \"a\", \"string\", \"broken\", \"into\", \"parts\"] number : 5 or 3.1415 boolean : true for Yes or false for No Every VALUE must have a trailing comma ( , ), except the last must not.","title":"config.json"},{"location":"setup/configure/#defaults","text":"Defaults were selected based on testing with lowest-recommended hardware. Baseline Command: ffmpeg -y -loglevel warning -nostdin -nostats \\ -t 00:10:00 -f alsa -i plughw \\ -t 00:10:00 -f v4l2 -i /dev/video0 \\ -map 0:a -c:a pcm_s16le -ar 48000 -ac 1 -f wav - \\ -filter_complex [1:v]...[dtstamp] -map 0:a -map [dtstamp] \\ -c:a pcm_s16le -ar 48000 -ac 1 -c:v libx264 -tune zerolatency baseline.mkv \\ >/dev/null Test-Driven Defaults: Encoder Documentation <https://trac.ffmpeg.org/wiki/Encode/H.264> __ -t <time> must be set prior to each input -tune zerolatency is required for software encoding on low-end cpu -bufsize 64M : Very large buffer to helps avoid processing spikes -crf 23 : Default is best; 25 reduces size by 30%, but 24 creates movement -maxrate 3M : Hard quality limit, based on NO hardware encoding 1080p recordings will see quality improvement up to about 7M Larger value creates larger files and XBUF for CPU-only encoding -preset fast : Yield fewest XRUN errors -framerate 15 : Fast enough to catch most movement","title":"Defaults"},{"location":"setup/hardware/","text":"Hardware Selection The financial investment required for this project comes down to hardware selection. The hardware required: Training Device: Typically the same laptop being used to set things up Monitoring Device: Low-power mini-PC with a few USB ports Microphone: The sensor that detects disturbing audio Camera: The sensor that shows proof of audio source Training Device A laptop (or desktop) of any age will work great for creating a trained model. CUDA-supporting GPUs, like Nvidia, can improve training time by up to 20%. Any currently-owned laptop with a webcam and microphone is likely a great option to try out this project, before deciding to purchase any additional hardware. Monitoring Device Although much of DTrack can easily run on a Raspberry Pi, these devices lack a \"hardware video en coder\", making video generation a very intensive process. This limits recording to about 3M/s, which is the extreme low side of 1080p. Fortunately, there are countless mini-PCs with hardware en coders that can tackle high-quality 4k video with ease, making storage size the next bottleneck. Any mini-PC with one of the following CPUs should be great picks: Intel Celeron (N150+) Intel Gemini Lake (N4000+) Intel Jasper Lake (N5000+) AMD Ryzen Embedded (R2000+, 7000+, 8000+) Microphone: The trained model used for automatic detection will be created using audio samples that were created from this microphone. This makes it one of the most important hardware decisions for this project. Changing this will require recording new samples in order to train a new model. Many microphones are designed to eliminate audio that is likely to be clasified as disturbances, such as dog barks or car alarms. It is important to find a microphone that does not advertise features like noise cancelling and instead offers \"high sensitivity\" and a \"wide frequency response.\" Some great options include: Angetube USB Microphone Blue Snowflake Camera: The camera you choose must be able to capture enough detail to identify the origin of the noise, but that is all the detail that is required. There is no reason to find an expensive camera. Most modern webcams that claim 1080p will be capable of capturing enough detail to accompany a written report.","title":"Hardware Selection"},{"location":"setup/hardware/#hardware-selection","text":"The financial investment required for this project comes down to hardware selection. The hardware required: Training Device: Typically the same laptop being used to set things up Monitoring Device: Low-power mini-PC with a few USB ports Microphone: The sensor that detects disturbing audio Camera: The sensor that shows proof of audio source","title":"Hardware Selection"},{"location":"setup/hardware/#training-device","text":"A laptop (or desktop) of any age will work great for creating a trained model. CUDA-supporting GPUs, like Nvidia, can improve training time by up to 20%. Any currently-owned laptop with a webcam and microphone is likely a great option to try out this project, before deciding to purchase any additional hardware.","title":"Training Device"},{"location":"setup/hardware/#monitoring-device","text":"Although much of DTrack can easily run on a Raspberry Pi, these devices lack a \"hardware video en coder\", making video generation a very intensive process. This limits recording to about 3M/s, which is the extreme low side of 1080p. Fortunately, there are countless mini-PCs with hardware en coders that can tackle high-quality 4k video with ease, making storage size the next bottleneck. Any mini-PC with one of the following CPUs should be great picks: Intel Celeron (N150+) Intel Gemini Lake (N4000+) Intel Jasper Lake (N5000+) AMD Ryzen Embedded (R2000+, 7000+, 8000+) Microphone: The trained model used for automatic detection will be created using audio samples that were created from this microphone. This makes it one of the most important hardware decisions for this project. Changing this will require recording new samples in order to train a new model. Many microphones are designed to eliminate audio that is likely to be clasified as disturbances, such as dog barks or car alarms. It is important to find a microphone that does not advertise features like noise cancelling and instead offers \"high sensitivity\" and a \"wide frequency response.\" Some great options include: Angetube USB Microphone Blue Snowflake Camera: The camera you choose must be able to capture enough detail to identify the origin of the noise, but that is all the detail that is required. There is no reason to find an expensive camera. Most modern webcams that claim 1080p will be capable of capturing enough detail to accompany a written report.","title":"Monitoring Device"},{"location":"setup/install/","text":"Installing DTrack Todo This project was originally written in Python. The transition to golang began because of performance issues, but became moot after a few magical ffmpeg/x264 options were discovered. There is a chance that tfgo will not have enough support for this project, but we shall see ... holding off on this document until the project finally reaches beta.","title":"Easy Installation"},{"location":"setup/install/#installing-dtrack","text":"Todo This project was originally written in Python. The transition to golang began because of performance issues, but became moot after a few magical ffmpeg/x264 options were discovered. There is a chance that tfgo will not have enough support for this project, but we shall see ... holding off on this document until the project finally reaches beta.","title":"Installing DTrack"},{"location":"setup/options/","text":"Configuration Options Note Visit the Configuration File section for information about how to use these configuration options. workspace Location where audio and video data is stored. Option Name Description foo Fuz bar Buz Section: Recording Variable: workspace Environment: DTRACK_WORKSPACE Default: _workspace workspace_keep_temp Keep temporary review data once extracted. Section Recording Variable workspace_keep_temp Environment DTRACK_WORKSPACE\\_KEEP\\_TEMP Default false OLD Many of the record_ configuration options become part of a very large ffmpeg command and are broken up to help make sure everything goes into the right place. List audio devices: ffmpeg -loglevel warning -sources alsa Look for: Hardware device with all software conversions List video devices: v4l2-ctl --list-devices --all Audio capture devices and their capabilities can be listed using: .. code-block:: sh ffmpeg -loglevel warning -sources alsa Sample Output: .. code-block:: sh Auto-detected sources for alsa: null [Discard all samples (playback) or generate zero samples (capture)] hw:CARD=Snowflake,DEV=0 [Direct hardware device without any conversions] plughw:CARD=Snowflake,DEV=0 [Hardware device with all software conversions] default:CARD=Snowflake [Default Audio Device] sysdefault:CARD=Snowflake [Default Audio Device] front:CARD=Snowflake,DEV=0 [Front output / input] dsnoop:CARD=Snowflake,DEV=0 [Direct sample snooping device] In the above example, hw:CARD=Snowflake,DEV=0 is one valid string that can be used for configuration. It is wise to test all available options to determine which will yield the most complete result. Video capture devices and their capabilities can be listed using: .. code-block:: sh v4l2-ctl --list-devices --all Sample Output: .. code-block:: sh Integrated Camera: Integrated C (usb-0000:64:00.4-1): /dev/video0 /dev/video1 /dev/video2 /dev/media0 /dev/media1 Lenovo 500 RGB Camera: Lenovo 5 (usb-0000:01:00.0-1.2): /dev/video3 /dev/video4 /dev/media2 [...] Format Video Capture: Width/Height : 1920/1080 Pixel Format : 'MJPG' (Motion-JPEG) [...] Streaming Parameters Video Capture: Capabilities : timeperframe Frames per second: 5.000 (5/1) [...] This sample output provided shows a webcam that can record at a maximum resolution of 1920x1080 at a framerate of 5. Note that only \"video\" devices should be used as a video capture device.","title":"Configuration Options"},{"location":"setup/options/#configuration-options","text":"Note Visit the Configuration File section for information about how to use these configuration options.","title":"Configuration Options"},{"location":"setup/options/#workspace","text":"Location where audio and video data is stored. Option Name Description foo Fuz bar Buz Section: Recording Variable: workspace Environment: DTRACK_WORKSPACE Default: _workspace","title":"workspace"},{"location":"setup/options/#workspace_keep_temp","text":"Keep temporary review data once extracted. Section Recording Variable workspace_keep_temp Environment DTRACK_WORKSPACE\\_KEEP\\_TEMP Default false","title":"workspace_keep_temp"},{"location":"setup/options/#old","text":"Many of the record_ configuration options become part of a very large ffmpeg command and are broken up to help make sure everything goes into the right place. List audio devices: ffmpeg -loglevel warning -sources alsa Look for: Hardware device with all software conversions List video devices: v4l2-ctl --list-devices --all Audio capture devices and their capabilities can be listed using: .. code-block:: sh ffmpeg -loglevel warning -sources alsa Sample Output: .. code-block:: sh Auto-detected sources for alsa: null [Discard all samples (playback) or generate zero samples (capture)] hw:CARD=Snowflake,DEV=0 [Direct hardware device without any conversions] plughw:CARD=Snowflake,DEV=0 [Hardware device with all software conversions] default:CARD=Snowflake [Default Audio Device] sysdefault:CARD=Snowflake [Default Audio Device] front:CARD=Snowflake,DEV=0 [Front output / input] dsnoop:CARD=Snowflake,DEV=0 [Direct sample snooping device] In the above example, hw:CARD=Snowflake,DEV=0 is one valid string that can be used for configuration. It is wise to test all available options to determine which will yield the most complete result. Video capture devices and their capabilities can be listed using: .. code-block:: sh v4l2-ctl --list-devices --all Sample Output: .. code-block:: sh Integrated Camera: Integrated C (usb-0000:64:00.4-1): /dev/video0 /dev/video1 /dev/video2 /dev/media0 /dev/media1 Lenovo 500 RGB Camera: Lenovo 5 (usb-0000:01:00.0-1.2): /dev/video3 /dev/video4 /dev/media2 [...] Format Video Capture: Width/Height : 1920/1080 Pixel Format : 'MJPG' (Motion-JPEG) [...] Streaming Parameters Video Capture: Capabilities : timeperframe Frames per second: 5.000 (5/1) [...] This sample output provided shows a webcam that can record at a maximum resolution of 1920x1080 at a framerate of 5. Note that only \"video\" devices should be used as a video capture device.","title":"OLD"}]}